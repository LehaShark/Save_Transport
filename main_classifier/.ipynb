{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pyaudio\n",
    "import time\n",
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa.display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AudioHandler(object):\n",
    "    def __init__(self):\n",
    "        self.FORMAT = pyaudio.paFloat32\n",
    "        self.CHANNELS = 1\n",
    "        self.RATE = 48000\n",
    "        self.CHUNK = 1024 * 2\n",
    "        self.p = None\n",
    "        self.stream = None\n",
    "\n",
    "    def start(self):\n",
    "        self.p = pyaudio.PyAudio()\n",
    "        self.stream = self.p.open(format=self.FORMAT,\n",
    "                                  channels=self.CHANNELS,\n",
    "                                  rate=self.RATE,\n",
    "                                  input=True,\n",
    "                                  output=False,\n",
    "                                  stream_callback=self.callback,\n",
    "                                  frames_per_buffer=self.CHUNK)\n",
    "\n",
    "    def stop(self):\n",
    "        self.stream.close()\n",
    "        self.p.terminate()\n",
    "\n",
    "    def callback(self, in_data, frame_count, time_info, flag):\n",
    "        numpy_array = np.frombuffer(in_data, dtype=np.float32)\n",
    "        librosa.feature.mfcc(numpy_array)\n",
    "        return None, pyaudio.paContinue\n",
    "\n",
    "    def mainloop(self):\n",
    "        while (self.stream.is_active()): # if using button you can set self.stream to 0 (self.stream = 0), otherwise you can use a stop condition\n",
    "            #data = stream.read(self.CHUNK)\n",
    "            #data_float = np.fromstring(data , dtype=np.float32)\n",
    "            #data_np = np.array(data_float , dtype='d')\n",
    "            #data in 1D array\n",
    "            #mfcc = librosa.feature.mfcc(data_np.flatten() , self.RATE)\n",
    "            #self.callback(self.stream, 10, 10, 10)\n",
    "            #print(mfcc)\n",
    "            time.sleep(2.0)\n",
    "\n",
    "\n",
    "audio = AudioHandler()\n",
    "audio.start()     # open the the stream\n",
    "#audio.mainloop()  # main operations with librosa\n",
    "audio.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_spectrogram(y, sample_rate):\n",
    "    \n",
    "    plt.interactive(False)\n",
    "    #clip, sample_rate = librosa.load(filename, sr=None)\n",
    "        \n",
    "    fig = plt.figure(figsize=[0.72,0.72])\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.axes.get_xaxis().set_visible(False)\n",
    "    ax.axes.get_yaxis().set_visible(False)\n",
    "    ax.set_frame_on(False)\n",
    "    spectrogram = librosa.feature.melspectrogram(y=y, sr=sample_rate)\n",
    "    librosa.display.specshow(librosa.power_to_db(spectrogram, ref=np.max))\n",
    "\n",
    "    \n",
    "    #filename = path\n",
    "    #plt.savefig(filename, dpi=400, bbox_inches='tight',pad_inches=0)\n",
    "    plt.close()    \n",
    "    fig.clf()\n",
    "    plt.close(fig)\n",
    "    plt.close('all')\n",
    "    \n",
    "    return spectrogram\n",
    "    del filename,clip,sample_rate,fig,ax,S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import librosa\n",
    "\n",
    "def feature_extract(y, sr):\n",
    "    \"\"\"\n",
    "    Define function that takes in a file an returns features in an array\n",
    "    \"\"\"\n",
    "    \n",
    "    #get wave representation\n",
    "    #y, sr = librosa.load(file)\n",
    "    #print(y)    \n",
    "    #determine if instruemnt is harmonic or percussive by comparing means\n",
    "    y_harmonic, y_percussive = librosa.effects.hpss(y)\n",
    "    if np.mean(y_harmonic)>np.mean(y_percussive):\n",
    "        harmonic=1\n",
    "    else:\n",
    "        harmonic=0\n",
    "        \n",
    "    #Mel-frequency cepstral coefficients (MFCCs)\n",
    "    mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)\n",
    "    #temporal averaging\n",
    "    mfcc=np.mean(mfcc,axis=1)\n",
    "    \n",
    "    #get the mel-scaled spectrogram\n",
    "    spectrogram = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=128,fmax=8000)  \n",
    "    #temporally average spectrogram\n",
    "    spectrogram = np.mean(spectrogram, axis = 1)\n",
    "    \n",
    "    #compute chroma energy\n",
    "    chroma = librosa.feature.chroma_cens(y=y, sr=sr)\n",
    "    #temporally average chroma\n",
    "    chroma = np.mean(chroma, axis = 1)\n",
    "    \n",
    "    #compute spectral contrast\n",
    "    contrast = librosa.feature.spectral_contrast(y=y, sr=sr)\n",
    "    contrast = np.mean(contrast, axis= 1)\n",
    "    \n",
    "    return [harmonic, mfcc, spectrogram, chroma, contrast]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* recording\n",
      "* done recording\n",
      "<class 'bytes'>\n"
     ]
    }
   ],
   "source": [
    "import pyaudio\n",
    "import wave\n",
    "\n",
    "CHUNK = 1024\n",
    "FORMAT = pyaudio.paFloat32\n",
    "CHANNELS = 2\n",
    "RATE = 44100\n",
    "RECORD_SECONDS = 1\n",
    "#WAVE_OUTPUT_FILENAME = \"output.wav\"\n",
    "\n",
    "p = pyaudio.PyAudio()\n",
    "\n",
    "stream = p.open(format=FORMAT,\n",
    "                channels=CHANNELS,\n",
    "                rate=RATE,\n",
    "                input=True,\n",
    "                frames_per_buffer=CHUNK)\n",
    "\n",
    "print(\"* recording\")\n",
    "\n",
    "frames = []\n",
    "\n",
    "for i in range(0, int(RATE / CHUNK * RECORD_SECONDS)):\n",
    "    data = stream.read(CHUNK)\n",
    "    frames.append(data)\n",
    "\n",
    "print(\"* done recording\")\n",
    "# print(type(frames))\n",
    "# print(type(frames[0]))\n",
    "# print(frames[0])\n",
    "\n",
    "\n",
    "all_frames = b''.join(frames)\n",
    "print(type(all_frames))\n",
    "\n",
    "# byte_sample = []\n",
    "# for chunk in frames: \n",
    "#     byte_sample.append(chunk)\n",
    "\n",
    "# print(type(byte_sample[0]))\n",
    "# print(byte_sample[0])\n",
    "\n",
    "numpy_array = np.frombuffer(all_frames, dtype=np.float32)\n",
    "#print(librosa.feature.mfcc(numpy_array))\n",
    "#print(numpy_array)\n",
    "feature = feature_extract(numpy_array, RATE)\n",
    "#print(feature)\n",
    "sp = create_spectrogram(numpy_array, RATE)\n",
    "\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "# fig, ax = plt.subplots()\n",
    "# img = librosa.display.specshow(feature[0], x_axis='time', ax=ax)\n",
    "# fig.colorbar(img, ax=ax)\n",
    "# ax.set(title='MFCC')\n",
    "\n",
    "stream.stop_stream()\n",
    "stream.close()\n",
    "p.terminate()\n",
    "\n",
    "\n",
    "# wf = wave.open(WAVE_OUTPUT_FILENAME, 'wb')\n",
    "# wf.setnchannels(CHANNELS)\n",
    "# wf.setsampwidth(p.get_sample_size(FORMAT))\n",
    "# wf.setframerate(RATE)\n",
    "# wf.writeframes(b''.join(frames))\n",
    "# wf.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.2247127e-01 1.3937783e-01 2.0139065e-01 ... 6.0550743e-03\n",
      "  2.7396217e-02 4.1290749e-02]\n",
      " [3.5348458e-03 1.4027502e-02 4.0088795e-02 ... 4.3804222e-03\n",
      "  1.3157947e-02 1.0531223e-02]\n",
      " [2.8195092e-03 3.0430544e-03 4.6847635e-03 ... 2.5031155e-03\n",
      "  4.2372551e-03 1.9034982e-03]\n",
      " ...\n",
      " [4.1758107e-05 4.8754871e-05 4.2025189e-05 ... 3.9467224e-05\n",
      "  5.1315503e-05 3.8392245e-05]\n",
      " [4.4430544e-05 5.5644832e-05 7.0158123e-05 ... 3.8467646e-05\n",
      "  4.5341374e-05 4.7531790e-05]\n",
      " [6.3648178e-05 5.8805996e-05 5.4033248e-05 ... 4.8561513e-05\n",
      "  5.4146240e-05 5.8027064e-05]]\n"
     ]
    }
   ],
   "source": [
    "print(sp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.QuadMesh at 0x7f51d8b5c250>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "librosa.display.specshow(librosa.power_to_db(sp, ref=np.max))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.01024908 0.9900153 ]]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "#from data_prep import valik\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from PIL import Image, ImageFont, ImageDraw\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "model = load_model('/home/aigaf/Downloads/Telegram Desktop/save_1.h5')\n",
    "\n",
    "\n",
    "# path_to_img = 'cut1.jpg'\n",
    "# img = Image.open(path_to_img)\n",
    "# img_arr = np.asarray(img)\n",
    "img_arr = sp\n",
    "# print(img_arr.shape, img_arr)\n",
    "img_norm = img_arr/255\n",
    "img_size = img_norm.resize((150, 150, 3))\n",
    "img_compl = img_norm.reshape(-1, 150, 150, 3)\n",
    "# print(img_compl)\n",
    "\n",
    "#results = model.evaluate(valik)\n",
    "#print('loss, accuracy =', results)\n",
    "\n",
    "\n",
    "final_res = model.predict(img_compl)\n",
    "print(final_res)\n",
    "# data = {'y_Actual':    [ tuple(i) for i in valik[1][1]],\n",
    "#         'y_Predicted': [ tuple(i) for i in final_res]\n",
    "#         }\n",
    "#\n",
    "# df = pd.DataFrame(data, columns=['y_Actual','y_Predicted'])\n",
    "# print (df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.7 64-bit ('base': conda)",
   "language": "python",
   "name": "python377jvsc74a57bd00d537df178d4a96c2cf8ca99df555b0d4bf3b31be3996b0ee2dcd6eb18f548f4"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "metadata": {
   "interpreter": {
    "hash": "0d537df178d4a96c2cf8ca99df555b0d4bf3b31be3996b0ee2dcd6eb18f548f4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
