{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "15cc8577",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pyaudio\n",
    "import time\n",
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa.display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c9fded80",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AudioHandler(object):\n",
    "    def __init__(self):\n",
    "        self.FORMAT = pyaudio.paFloat32\n",
    "        self.CHANNELS = 1\n",
    "        self.RATE = 48000\n",
    "        self.CHUNK = 1024 * 2\n",
    "        self.p = None\n",
    "        self.stream = None\n",
    "\n",
    "    def start(self):\n",
    "        self.p = pyaudio.PyAudio()\n",
    "        self.stream = self.p.open(format=self.FORMAT,\n",
    "                                  channels=self.CHANNELS,\n",
    "                                  rate=self.RATE,\n",
    "                                  input=True,\n",
    "                                  output=False,\n",
    "                                  stream_callback=self.callback,\n",
    "                                  frames_per_buffer=self.CHUNK)\n",
    "\n",
    "    def stop(self):\n",
    "        self.stream.close()\n",
    "        self.p.terminate()\n",
    "\n",
    "    def callback(self, in_data, frame_count, time_info, flag):\n",
    "        numpy_array = np.frombuffer(in_data, dtype=np.float32)\n",
    "        librosa.feature.mfcc(numpy_array)\n",
    "        return None, pyaudio.paContinue\n",
    "\n",
    "    def mainloop(self):\n",
    "        while (self.stream.is_active()): # if using button you can set self.stream to 0 (self.stream = 0), otherwise you can use a stop condition\n",
    "            #data = stream.read(self.CHUNK)\n",
    "            #data_float = np.fromstring(data , dtype=np.float32)\n",
    "            #data_np = np.array(data_float , dtype='d')\n",
    "            #data in 1D array\n",
    "            #mfcc = librosa.feature.mfcc(data_np.flatten() , self.RATE)\n",
    "            #self.callback(self.stream, 10, 10, 10)\n",
    "            #print(mfcc)\n",
    "            time.sleep(2.0)\n",
    "\n",
    "\n",
    "audio = AudioHandler()\n",
    "audio.start()     # open the the stream\n",
    "#audio.mainloop()  # main operations with librosa\n",
    "audio.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "462aa12e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_spectrogram(y, sample_rate):\n",
    "    \n",
    "    plt.interactive(False)\n",
    "    #clip, sample_rate = librosa.load(filename, sr=None)\n",
    "        \n",
    "    fig = plt.figure(figsize=[0.72,0.72])\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.axes.get_xaxis().set_visible(False)\n",
    "    ax.axes.get_yaxis().set_visible(False)\n",
    "    ax.set_frame_on(False)\n",
    "    spectrogram = librosa.feature.melspectrogram(y=y, sr=sample_rate)\n",
    "    librosa.display.specshow(librosa.power_to_db(spectrogram, ref=np.max))\n",
    "\n",
    "    \n",
    "    #filename = path\n",
    "    #plt.savefig(filename, dpi=400, bbox_inches='tight',pad_inches=0)\n",
    "    plt.close()    \n",
    "    fig.clf()\n",
    "    plt.close(fig)\n",
    "    plt.close('all')\n",
    "    \n",
    "    return spectrogram\n",
    "    del filename,clip,sample_rate,fig,ax,S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9223e08c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import librosa\n",
    "\n",
    "def feature_extract(y, sr):\n",
    "    \"\"\"\n",
    "    Define function that takes in a file an returns features in an array\n",
    "    \"\"\"\n",
    "    \n",
    "    #get wave representation\n",
    "    #y, sr = librosa.load(file)\n",
    "    #print(y)    \n",
    "    #determine if instruemnt is harmonic or percussive by comparing means\n",
    "    y_harmonic, y_percussive = librosa.effects.hpss(y)\n",
    "    if np.mean(y_harmonic)>np.mean(y_percussive):\n",
    "        harmonic=1\n",
    "    else:\n",
    "        harmonic=0\n",
    "        \n",
    "    #Mel-frequency cepstral coefficients (MFCCs)\n",
    "    mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)\n",
    "    #temporal averaging\n",
    "    mfcc=np.mean(mfcc,axis=1)\n",
    "    \n",
    "    #get the mel-scaled spectrogram\n",
    "    spectrogram = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=128,fmax=8000)  \n",
    "    #temporally average spectrogram\n",
    "    spectrogram = np.mean(spectrogram, axis = 1)\n",
    "    \n",
    "    #compute chroma energy\n",
    "    chroma = librosa.feature.chroma_cens(y=y, sr=sr)\n",
    "    #temporally average chroma\n",
    "    chroma = np.mean(chroma, axis = 1)\n",
    "    \n",
    "    #compute spectral contrast\n",
    "    contrast = librosa.feature.spectral_contrast(y=y, sr=sr)\n",
    "    contrast = np.mean(contrast, axis= 1)\n",
    "    \n",
    "    return [harmonic, mfcc, spectrogram, chroma, contrast]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dba2bacc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* recording\n",
      "* done recording\n",
      "<class 'bytes'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alexe\\anaconda3\\envs\\audioClsfy\\lib\\site-packages\\librosa\\core\\spectrum.py:222: UserWarning: n_fft=1024 is too small for input signal of length=688\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pyaudio\n",
    "import wave\n",
    "\n",
    "CHUNK = 1024\n",
    "FORMAT = pyaudio.paFloat32\n",
    "CHANNELS = 2\n",
    "RATE = 44100\n",
    "RECORD_SECONDS = 1\n",
    "#WAVE_OUTPUT_FILENAME = \"output.wav\"\n",
    "\n",
    "p = pyaudio.PyAudio()\n",
    "\n",
    "stream = p.open(format=FORMAT,\n",
    "                channels=CHANNELS,\n",
    "                rate=RATE,\n",
    "                input=True,\n",
    "                frames_per_buffer=CHUNK)\n",
    "\n",
    "print(\"* recording\")\n",
    "\n",
    "frames = []\n",
    "\n",
    "for i in range(0, int(RATE / CHUNK * RECORD_SECONDS)):\n",
    "    data = stream.read(CHUNK)\n",
    "    frames.append(data)\n",
    "\n",
    "print(\"* done recording\")\n",
    "# print(type(frames))\n",
    "# print(type(frames[0]))\n",
    "# print(frames[0])\n",
    "\n",
    "\n",
    "all_frames = b''.join(frames)\n",
    "print(type(all_frames))\n",
    "\n",
    "# byte_sample = []\n",
    "# for chunk in frames: \n",
    "#     byte_sample.append(chunk)\n",
    "\n",
    "# print(type(byte_sample[0]))\n",
    "# print(byte_sample[0])\n",
    "\n",
    "numpy_array = np.frombuffer(all_frames, dtype=np.float32)\n",
    "#print(librosa.feature.mfcc(numpy_array))\n",
    "#print(numpy_array)\n",
    "feature = feature_extract(numpy_array, RATE)\n",
    "#print(feature)\n",
    "sp = create_spectrogram(numpy_array, RATE)\n",
    "\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "# fig, ax = plt.subplots()\n",
    "# img = librosa.display.specshow(feature[0], x_axis='time', ax=ax)\n",
    "# fig.colorbar(img, ax=ax)\n",
    "# ax.set(title='MFCC')\n",
    "\n",
    "stream.stop_stream()\n",
    "stream.close()\n",
    "p.terminate()\n",
    "\n",
    "\n",
    "# wf = wave.open(WAVE_OUTPUT_FILENAME, 'wb')\n",
    "# wf.setnchannels(CHANNELS)\n",
    "# wf.setsampwidth(p.get_sample_size(FORMAT))\n",
    "# wf.setframerate(RATE)\n",
    "# wf.writeframes(b''.join(frames))\n",
    "# wf.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e8e4aafa",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3.9706931e-09 2.4142215e-09 1.3809435e-08 ... 1.5074582e-04\n",
      "  4.2552149e-04 4.2727668e-04]\n",
      " [1.3827980e-09 3.1443972e-09 1.6662636e-08 ... 4.3864486e-05\n",
      "  1.6806768e-04 6.3795713e-04]\n",
      " [8.4085500e-10 6.0934469e-10 1.6752608e-08 ... 1.5807342e-06\n",
      "  1.3177765e-04 5.0049485e-04]\n",
      " ...\n",
      " [5.8839311e-09 5.0183311e-09 1.2089104e-08 ... 7.9766269e-06\n",
      "  1.5724194e-05 2.0730360e-05]\n",
      " [5.8050471e-09 7.0301795e-09 1.1833212e-08 ... 8.1627859e-06\n",
      "  1.8344264e-05 2.0924334e-05]\n",
      " [8.7152143e-09 9.2973949e-09 8.7624397e-09 ... 2.2256952e-06\n",
      "  3.1861309e-06 3.9871452e-06]]\n"
     ]
    }
   ],
   "source": [
    "print(sp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "76e27f17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.QuadMesh at 0x250d56da2b0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "librosa.display.specshow(librosa.power_to_db(sp, ref=np.max))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6b280631",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.01024908 0.9900153 ]]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "#from data_prep import valik\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from PIL import Image, ImageFont, ImageDraw\n",
    "import numpy as np\n",
    "\n",
    "path = load_model(r'D:\\save_1.h5')\n",
    "\n",
    "model = load_model('/home/aigaf/Downloads/Telegram Desktop/save_1.h5')\n",
    "\n",
    "\n",
    "# path_to_img = 'cut1.jpg'\n",
    "# img = Image.open(path_to_img)\n",
    "# img_arr = np.asarray(img)\n",
    "img_arr = sp\n",
    "# print(img_arr.shape, img_arr)\n",
    "img_norm = img_arr/255\n",
    "img_size = img_norm.resize((150, 150, 3))\n",
    "img_compl = img_norm.reshape(-1, 150, 150, 3)\n",
    "# print(img_compl)\n",
    "\n",
    "#results = model.evaluate(valik)\n",
    "#print('loss, accuracy =', results)\n",
    "\n",
    "\n",
    "final_res = model.predict(img_compl)\n",
    "print(final_res)\n",
    "# data = {'y_Actual':    [ tuple(i) for i in valik[1][1]],\n",
    "#         'y_Predicted': [ tuple(i) for i in final_res]\n",
    "#         }\n",
    "#\n",
    "# df = pd.DataFrame(data, columns=['y_Actual','y_Predicted'])\n",
    "# print (df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1233c1db",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "metadata": {
   "interpreter": {
    "hash": "0d537df178d4a96c2cf8ca99df555b0d4bf3b31be3996b0ee2dcd6eb18f548f4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
