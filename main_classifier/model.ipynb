{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1696 images belonging to 2 classes.\n",
      "Found 60 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "# data preparation\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "from tensorflow.keras import backend\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import layers\n",
    "from keras import models\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import keras.backend as K\n",
    "import librosa\n",
    "import librosa.display\n",
    "import pylab\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import figure\n",
    "import gc\n",
    "from path import Path\n",
    "\n",
    "\n",
    "from keras_preprocessing.image import ImageDataGenerator\n",
    "train_datagen = ImageDataGenerator(rescale=1.0/255)\n",
    "test_datagen = ImageDataGenerator(rescale=1.0/255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        r'D:\\reposetory\\Save_Transport\\dataset\\train',\n",
    "        target_size=(150, 150),\n",
    "        batch_size=20)\n",
    "\n",
    "valik = test_datagen.flow_from_directory(\n",
    "        r'D:\\reposetory\\Save_Transport\\dataset\\test',\n",
    "        target_size=(150, 150),\n",
    "        batch_size=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "24/24 - 8s - loss: 0.4742 - accuracy: 0.7917 - val_loss: 0.4762 - val_accuracy: 0.6833\n",
      "Epoch 2/10\n",
      "24/24 - 9s - loss: 0.2950 - accuracy: 0.8250 - val_loss: 0.3209 - val_accuracy: 0.9000\n",
      "Epoch 3/10\n",
      "24/24 - 8s - loss: 0.2511 - accuracy: 0.8562 - val_loss: 1.0799 - val_accuracy: 0.5000\n",
      "Epoch 4/10\n",
      "24/24 - 8s - loss: 0.2992 - accuracy: 0.8403 - val_loss: 0.3363 - val_accuracy: 0.8500\n",
      "Epoch 5/10\n",
      "24/24 - 8s - loss: 0.2621 - accuracy: 0.8592 - val_loss: 0.3290 - val_accuracy: 0.9167\n",
      "Epoch 6/10\n",
      "24/24 - 8s - loss: 0.2153 - accuracy: 0.8571 - val_loss: 0.3923 - val_accuracy: 0.7500\n",
      "Epoch 7/10\n",
      "24/24 - 9s - loss: 0.2542 - accuracy: 0.8354 - val_loss: 0.2572 - val_accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "24/24 - 8s - loss: 0.2659 - accuracy: 0.8313 - val_loss: 0.3284 - val_accuracy: 0.8500\n",
      "Epoch 9/10\n",
      "24/24 - 9s - loss: 0.2572 - accuracy: 0.8256 - val_loss: 0.4488 - val_accuracy: 0.5000\n",
      "Epoch 10/10\n",
      "24/24 - 8s - loss: 0.2163 - accuracy: 0.8750 - val_loss: 0.2144 - val_accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "# model\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras.backend as K\n",
    "def weighted_binary_crossentropy(y_true, y_pred):\n",
    "    weights = (tf.math.abs(y_true-1) * 59.) + 1.\n",
    "    bce = tf.keras.losses.binary_crossentropy(y_true, y_pred)\n",
    "    weighted_bce = K.mean(bce * weights)\n",
    "    return weighted_bce\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(16, (3, 3), input_shape=(150, 150, 3)),\n",
    "    tf.keras.layers.Conv2D(16, (3, 3)),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    tf.keras.layers.LeakyReLU(alpha=0.3),\n",
    "    tf.keras.layers.Conv2D(32, (3, 3)),\n",
    "    tf.keras.layers.Conv2D(32, (3, 3)),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    tf.keras.layers.LeakyReLU(alpha=0.3),\n",
    "    tf.keras.layers.Conv2D(64, (3, 3)),\n",
    "    tf.keras.layers.Conv2D(64, (3, 3)),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    tf.keras.layers.LeakyReLU(alpha=0.3),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(512),\n",
    "    tf.keras.layers.LeakyReLU(alpha=0.3),\n",
    "    tf.keras.layers.Dense(2, activation='sigmoid')\n",
    "])\n",
    "\n",
    "\n",
    "# Настраиваем гиперпараметры нейронной сети\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Начинаем обучение\n",
    "history = model.fit(train_generator,\n",
    "                      validation_data=valik,\n",
    "                      steps_per_epoch=24,\n",
    "                      epochs=10,\n",
    "                      validation_steps=3,\n",
    "                      verbose=2)\n",
    "\n",
    "model.save('save_1.h5')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x000001770D70E430> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 0.2144 - accuracy: 1.0000\n",
      "\n",
      " loss, accuracy = [0.21437668800354004, 1.0] \n",
      "\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001770D80B3A0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "      y_Actual                 y_Predicted\n",
      "0   (1.0, 0.0)    (0.55965096, 0.40909812)\n",
      "1   (1.0, 0.0)     (0.6728145, 0.27684718)\n",
      "2   (1.0, 0.0)      (0.6597644, 0.2831859)\n",
      "3   (1.0, 0.0)     (0.5751781, 0.39527416)\n",
      "4   (0.0, 1.0)   (0.025350213, 0.97447234)\n",
      "5   (0.0, 1.0)  (0.0013165176, 0.99871767)\n",
      "6   (0.0, 1.0)    (0.021077842, 0.9793423)\n",
      "7   (1.0, 0.0)    (0.58968014, 0.37217873)\n",
      "8   (1.0, 0.0)      (0.6320741, 0.3225786)\n",
      "9   (1.0, 0.0)     (0.7036094, 0.23707208)\n",
      "10  (1.0, 0.0)     (0.6628956, 0.28185385)\n",
      "11  (1.0, 0.0)     (0.57092774, 0.3967358)\n",
      "12  (1.0, 0.0)      (0.6399077, 0.3101769)\n",
      "13  (0.0, 1.0)    (0.017175227, 0.9825889)\n",
      "14  (0.0, 1.0)    (0.017175227, 0.9825889)\n",
      "15  (1.0, 0.0)     (0.64389443, 0.3025397)\n",
      "16  (0.0, 1.0)    (0.00871408, 0.99098253)\n",
      "17  (0.0, 1.0)   (9.768778e-05, 0.9998743)\n",
      "18  (0.0, 1.0)    (0.015492231, 0.9853165)\n",
      "19  (0.0, 1.0)   (0.0023209155, 0.9973476)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "#from data_prep import valik\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from PIL import Image, ImageFont, ImageDraw\n",
    "\n",
    "\n",
    "model = load_model(r'D:\\reposetory\\Save_Transport\\main_classifier\\save_1.h5')\n",
    "\n",
    "\n",
    "results = model.evaluate(valik)\n",
    "print('\\n loss, accuracy =', results, '\\n')\n",
    "\n",
    "\n",
    "final_res = model.predict(valik[1][0])\n",
    "\n",
    "data = {'y_Actual':    [ tuple(i) for i in valik[1][1]],\n",
    "        'y_Predicted': [ tuple(i) for i in final_res]\n",
    "        }\n",
    "\n",
    "df = pd.DataFrame(data, columns=['y_Actual','y_Predicted'])\n",
    "print (df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
